# 머신러닝이란?



컴퓨터 과학에서 컴퓨터를 적극적으로 이용한 통계학을 의미.

통계학과 중복되는 부분도 있지만, 컴퓨팅에 중점을 둔 기법이나 정보 이론에 뿌리박은 기법 등 다른 전개를 보이는 부분도 많다.



- 지도 학습

  - 입력데이터(질문)와 출력 데이터(답)가 세트로 되어있는 데이터를 다룬다.

  - ex) 주택가격을 방의 개수, 대지 면적, 주택환경지수 등의 특징량을 이용해 회귀모델로 예측하는 문제

  - 회귀, 분류, 랭킹

    

- 비지도 학습

  - 입력 데이터만 주어진 상황을 가리킨다.
  
  - 클러스터링, 차원축소, 행렬보완, 다양체학습 등
  
    

- 준지도 학습
  - 일부 데이터에는 출력 데이터가 있지만, 나머지는 출력 데이터가 없는 상황을 가리킨다. 



## 지도학습

#### 지도 학습의 목적

예를 들어, 주택 가격을 예측하고 싶다고 할 때

우리에게 주어진 feature는 방의 개수, 대지 면적, 주택환경지수

주택가격을 Y, feature를 X로 표현하면


$$
Y = f(X) + ε
$$
f는 Y와 X를 연결하는 함수, ε(엡실론)은 오차항(X와는 관계없는 랜덤 노이즈)을 나타낸다. 

**지도학습의 목적은 이 f 를 추정하는 것.**



출럭데이터와 입력 데이터를 연결하는 함수를 학습하면?

- 예측할 수 있게 된다.
- 데이터를 해석할 수 있게 된다.



왜 f를 추정하고 싶을까?

- f를 추정함으로써 예측할 수 있게 된다.

처음에 주어진 데이터(학습데이터)를 이용해 추정한 함수를 바탕으로 주택 가격이 불분명한 주거에 대해 예측할 수 있게 된다.



- 데이터 해석이 가능하다.

만약 f가 선형회귀처럼 아주 이해하기 쉬운 모델이라면 상관관계를 분석하기도 쉽다. 

또한 선형회귀의 경우, 계수를 보기만 해도 각 변수가 양의 상관을 가지는지 음의 상관을 가지는지도 한눈에 알 수 있다. 



## 훈련오차와 테스트오차

#### 일반화 성능이란?

추정시에는 사용하지 않았던 데이터로 측정한 성능



어떤 데이터에서 발견한 패턴(규칙성)이 그 데이터로 잘맞는 건 당연하다.

⇒ 미지의 데이터(학습에 사용하지 않은 데이터)로 잘 맞는지 검증한다.

⇒ 모델의 일반화 성능을 측정한다.(시험데이터에 잘 들어 맞는가?)



머신러닝에서는 데이터를 학습데이터와 시험데이터로 구별하는 것이 일반적이다.  물론 데이터를 입수할 때 그렇게 구별된 경우는 거의 없으므로, **분석자가 타당한 형태로 구별해서 의사적으로 시험데이터를 설정**한다.



- 데이터를 생성한 배후 모델이 항상 같다고 여겨지면?

학습데이터와 시험데이터를 랜덤하게 원하는 비율로 나누는 방법!



- 시점 정볼르 포함해 각 레코드를 생선한 배후 모델이 시점에 따라 변화하는 것이 전제라면?

과거 데이터와 미래 데이터로 나누는 것이 타당!



## 모수적 모델과 비모수적 모델

- 모수적 모델이란?
  - 수식을 이용해, 명시적으로 함수를 정의한 모델.
  - 모수적 모델의 장점
    - 안정적으로 추정한느데 필요한 데이터가 비교적 적다
    - 모델 추정도 간단하다
    - 해석 가능성이 높은 경우가 많다
  - 모수적 모델의 단점
    - 모델 가정이 나쁘면 체계적으로 예측을 벗어나게 된다.
- 비모수적 모델이란?
  - 데이터에 맞춰 모델을 구축
  - 비모수적 모델의 장점
    - 실제 모델에 가까운 형태로 모델을 구성할 수 있다
  - 비모수적 모델의 단점
    - 안정적으로 추정한느 데 필요한 데이터가 비교적 많다
    - 모델 추정이 어려운 경우가 많다
    - 해석 가능성이 희생되기도 한다.



## 추정법

예측이 목적이라면?

모델은 시험 데이터의 손실을 최소화하는 모델이 가장 좋은 모델!



주의할 점

1. 학습 데이터와 시험 데이터가 **같은 성질을 가진 데이터(데이터를 생성한 배후 모델이 같다)**가 아니면 아무리 학습 데이터로 손실을 최소화해도 시험 데이터 상에서는 도움이 되지 않는다.

   ex) 야구 선수 연봉 예측을 하고 싶은데, 축구 선수 연봉으로 학습한 모델로 예측하는 경우

2. 모델이 지나치게 유연하면, 학습데이터에 과잉 적합해 버려, **과적합(overfitting)으로 불리는 상태가 발생**한다.

   ex)과거 판매 패턴을 전부 학습해 버린 모델. 데이터 자체를 학습해도 새로운 데이터에는 대응할 수 없다.