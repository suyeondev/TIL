# 분류

## 로지스틱 회귀란?

**로지스틱 회귀(Logistic Regression)**는 회귀를 사용하여 데이터가 어떤 범주에 속할 확률을 0에서 1 사이의 값으로 예측하고 그 확률에 따라 가능성이 더 높은 범주에 속하는 것으로 분류해주는 지도 학습 알고리즘이다.



선형회귀를 적용할 경우, 예측할 때, -0.3이나 1.3 등 애초에 확률이 아닌 값을 출력하게 된다. 그래서, 출력 변수가 두 가지(0이나 1)인 데이터를 자연스럽게 모델링하고자, 0과 1이 나타나는 확률값이 출력되도록 선형회귀 모델을 확장한 것이다.



**이항 로지스틱 회귀** 

- 종속 변수의 결과가 (성공, 실패) 와 같이 2개의 카테고리가 존재하는 것을 의미한다.

- 2개의 카테고리는 0과 1로 나타내어지고 각각의 카테고리로 분류될 확률의 합은 1이 된다.

  

**다항 로지스틱 회귀**

- 종속형 변수가 (맑음, 흐림, 비)와 같이 2개 이상의 카테고리로 분류되는 것을 의미한다.



## 서포트 벡터 머신

**서포트 벡터 머신**(support vector machine, **SVM**)은 기계 학습의 분야 중 하나로 패턴 인식, 자료 분석을 위한 지도 학습모델이며, 주로 분류와 회귀 분석을 위해 사용한다. 

두 카테고리 중 어느 하나에 속한 데이터의 집합이 주어졌을 때, SVM 알고리즘은 주어진 데이터 집합을 바탕으로 하여 새로운 데이터가 어느 카테고리에 속할지 판단하는 비확률적이진 선형 분류 모델을 만든다. 만들어진 분류 모델은 데이터가 사상된 공간에서 경계로 표현되는데 SVM 알고리즘은 그 중 가장 큰 폭을 가진 경계를 찾는 알고리즘이다. 



### 선형 서포트 벡터머신의 원리

2개의 속성을 이용해 라벨을 분류할 때 직선을 그어, 이 선보다 위면 O, 그렇지 않으면 △ 라는 식으로 나눌 수 있다.



#### 서포트 벡터란?

분리 초평면을 정의할 때 사용하는 몇개의 점을 의미한다.

서포트 벡터를 잘 활용하면 서포트 벡터 머신을 비선형으로 확장 가능하다.



### 특징량의 관계가 비선형이라면?

선형 서포트 벡터머신으로는 풀 수 없다.

속성이 3개로 늘어난다면 **결정 경계**는 ‘선’이 아닌 ‘평면’이 된다. **결정 경계**도 단순한 평면이 아닌 고차원이 될 텐데 이를 **“초평면(hyperplane)”**이라고 한다.

따라서, 커널로 초평면을 추정하여야 하기 때문에 커널을 잘 설계해서 해야 한다.



[참고문헌] - 그림으로 배우는 데이터과학 Data Science - 히사노 료헤이, 키와키 타이치 지음 김성훈 옮김

